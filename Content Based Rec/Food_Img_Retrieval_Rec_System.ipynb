{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I have used VGG16 pretrained Deep Neural network and clustering together to reach suitable results\n",
    "import os\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracts features from an image using the VGG16 model.\n",
    "def extract_vgg16_features(img_path, target_size=(224, 224)):\n",
    "    image = load_img(img_path, target_size=target_size)\n",
    "    image = img_to_array(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = image / 255.0  # Normalize pixel values to the range [0, 1]\n",
    "\n",
    "    model = VGG16(include_top=False, weights='imagenet', input_shape=(target_size[0], target_size[1], 3))\n",
    "    features = model.predict(image)\n",
    "    features = features.reshape((-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Builds an index of image features using k-means clustering\n",
    "def build_index(img_paths, num_clusters=40, target_size=(224, 224)):\n",
    "    all_features = []\n",
    "    for img_path in img_paths:                  #add all unique images in path to build index\n",
    "        features = extract_vgg16_features(img_path, target_size)\n",
    "        if features is not None:\n",
    "            all_features.append(features)\n",
    "\n",
    "    all_features = np.array(all_features)\n",
    "    kmeans = KMeans(n_clusters=num_clusters)\n",
    "    kmeans.fit(all_features)\n",
    "    return kmeans, all_features   # Return Array of image features used for clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves image features to an SQLite DB.\n",
    "def save_features_to_DB(DB_path, img_paths, all_features):\n",
    "    conn = sqlite3.connect(DB_path)       #establish and intilize connection\n",
    "    cursor = conn.cursor()  \n",
    "\n",
    "    cursor.execute('DROP TABLE IF EXISTS features')\n",
    "     #we have two columns in the DB : first is img_address(TEXT) and seconde is vector of image features(BLOB)\n",
    "    cursor.execute('''CREATE TABLE features (img_path TEXT PRIMARY KEY, features BLOB)''') \n",
    "\n",
    "    for i, img_path in enumerate(img_paths):\n",
    "        features_blob = all_features[i].tobytes()\n",
    "        cursor.execute('INSERT INTO features (img_path, features) VALUES (?, ?)', (img_path, features_blob))\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    Loads image features from an SQLite DB.\n",
    "def load_features_from_DB(DB_path):\n",
    "    conn = sqlite3.connect(DB_path)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    cursor.execute('SELECT img_path, features FROM features')\n",
    "    rows = cursor.fetchall()\n",
    "\n",
    "    img_paths = []\n",
    "    all_features = []\n",
    "\n",
    "    for row in rows:\n",
    "        img_paths.append(row[0])\n",
    "        features_blob = row[1]\n",
    "        features = np.frombuffer(features_blob, dtype=np.float32)\n",
    "        all_features.append(features)  #append all features of the images to all_features = [] \n",
    "\n",
    "    conn.close()\n",
    "    return img_paths, np.array(all_features)  #return all path and all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_cosine_similarity(features1, features2):\n",
    "\n",
    "    return cosine_similarity(features1.reshape(1, -1), features2.reshape(1, -1))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    Retrieves similar images based on a query image.\n",
    "def retrieve_similar_imgs(query_img_path, kmeans, all_features, num_results=3, target_size=(224, 224)):    \n",
    "    \"\"\"\n",
    "    tasks are Retrieves similar images based on a query image.\n",
    "\n",
    "    input Parameters:\n",
    "        query_image_path (str): The path of the query image.\n",
    "        kmeans (KMeans): The trained k-means clustering model.\n",
    "        all_features (numpy array): Array of image features used for clustering.\n",
    "        num_results (int, optional): Number of similar images to retrieve.\n",
    "        target_size (tuple, optional): The target size for resizing the image before feature extraction.\n",
    "                                    \n",
    "    Returns:\n",
    "        sorted_images (list): List of file paths of similar images, sorted by similarity.\n",
    "    \"\"\"\n",
    "    query_features = extract_vgg16_features(query_img_path, target_size)\n",
    "    query_features = query_features.reshape(1, -1)  # Reshape to 2D array\n",
    "\n",
    "    query_cluster = kmeans.predict(query_features)    # Predict the cluster of the query image using the trained k-means model\n",
    "    similar_img_indices = np.where(kmeans.labels_ == query_cluster)  #     # Find indices of images in the same cluster as the query image\n",
    "\n",
    "    # Initialize lists to store similar images and their creative similarities\n",
    "    similar_imgs = []\n",
    "    my_similarities = []\n",
    "    \n",
    "    for idx in similar_img_indices[0]:\n",
    "        img_path = img_paths[idx]\n",
    "        img_features = all_features[idx]\n",
    "        img_features = img_features.reshape(1, -1)  # Reshape to 2D array\n",
    "        similarity = cal_cosine_similarity(query_features, img_features)   # Calculate the cosine similarity between the query image and the current image\n",
    "        similar_imgs.append(img_path)          # Append the image path and similarity to the corresponding lists\n",
    "        my_similarities.append(similarity)\n",
    "\n",
    "    sorted_indices = np.argsort(my_similarities)[::-1]     # Sort the images based on the cosine similarity in descending order\n",
    "    sorted_imgs = [similar_imgs[idx] for idx in sorted_indices]\n",
    "    return sorted_imgs[:num_results]         # Return List of file paths of similar images, sorted by similarity.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    dataset_path = '/content/images/'\n",
    "    query_image_path = '/content/images/5.png'\n",
    "    database_path = '/content/vector-database.db'\n",
    "\n",
    "    img_paths = []\n",
    "    for file in os.listdir(dataset_path):\n",
    "        img_path = os.path.join(dataset_path, file)\n",
    "        img_paths.append(img_path)\n",
    "\n",
    "    print(\"Number of imgs in dataset:\", len(img_paths))\n",
    "    kmeans, all_features = build_index(img_paths, num_clusters=len(img_paths//5), target_size=(224, 224))\n",
    "    save_features_to_DB(DB_path, img_paths, all_features)\n",
    "\n",
    "    # After saving features to the DB, you can load them directly from the DB for fast retrieval\n",
    "    loaded_img_paths, loaded_all_features = load_features_from_DB(DB_path)\n",
    "\n",
    "    num_results = 3\n",
    "    similar_imgs = retrieve_similar_imgs(query_img_path, kmeans, loaded_all_features, num_results, target_size=(224, 224))\n",
    "\n",
    "    # Calculate cosine similarity for each pair of imgs\n",
    "    query_features = extract_vgg16_features(query_img_path, target_size=(224, 224))\n",
    "    my_similarities = []  #this similarity based on the cosine similarity metric\n",
    "    for img_path in similar_imgs:\n",
    "        img_features = extract_vgg16_features(img_path, target_size=(224, 224))\n",
    "        similarity = cal_cosine_similarity(query_features, img_features)\n",
    "        my_similarities.append(similarity)\n",
    "\n",
    "    # Display or process the retrieved similar imgs and creative similarities as needed\n",
    "    print(\"-> Similar imgs and cosine similarities:\")\n",
    "    for img_path, similarity in zip(similar_imgs, my_similarities):\n",
    "        print(f\"img: {img_path}, cosine Similarity: {similarity:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
